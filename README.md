# ML Interview Pro ğŸ¤–

AI-powered ML interview preparation chatbot for freshers.

---

<div align="center">
  <img src="assets/practical.jpg" width="80%">
</div>

---

<p align="center">
ğŸ¤– <b>ML Interview Pro</b><br>
Author: <b>Sakshi Tiwari</b>
</p>

---

## ğŸ¦¾ Introduction

**ML Interview Pro** is a smart AI-powered interview preparation chatbot designed for Machine Learning freshers.  
It provides personalized guidance, code examples, formulas, and career tips in a fresher-friendly way.

> Unlock ML concepts, practice questions, and real-world insights effortlessly.

---

## âœ¨ Features

ğŸ­ **Multiple Personas**: Mentor, Coder, Teacher, Interviewer  
ğŸ§  **Fresher-Friendly Guidance**  
ğŸ’¡ **Real-World Examples**  
ğŸ—ï¸ **Modular Architecture**  
ğŸ“Š **Progress Tracking & Analytics**

---

## ğŸ¯ Purpose

This project helps ML freshers prepare for interviews by simulating real Q&A sessions, offering conceptual clarity, and guiding them through practical implementation and math fundamentals.  
Itâ€™s built to be intuitive, empathetic, and technically sound â€” just like a real mentor.

---

<div align="center">
  <img src="assets/DEMO_ML.jpg" width="80%">
</div>

---

## ğŸ“Š System Workflow

```mermaid
graph TD
    %% DEMO_ML Flow 1
    A1[User Query] --> B1[Persona Selection]
    B1 --> C1[LLM Processing]
    C1 --> D1[Context-Aware Response]
    D1 --> E1[Interactive Learning]
    E1 --> F1[Progress Tracking]
    F1 --> Z[âŒ ERROR: Progress Monitoring Failed]

    %% Persona Branches
    B1 --> G1[ğŸ‘¨â€ğŸ« Mentor]
    B1 --> H1[ğŸ‘¨â€ğŸ’» Coder]
    B1 --> I1[ğŸ“š Teacher]
    B1 --> J1[ğŸ’¼ Interviewer]

    %% Learning Analytics Flow
    A2[User Input] --> B2[Input Processing]
    B2 --> C2[LLM Engine]
    C2 --> D2[Response Generation]
    D2 --> E2[Learning Analytics]
    E2 --> J2[Concept Tracking]
    E2 --> K2[Progress Monitoring]
    K2 --> Z[âŒ ERROR: Progress Monitoring Failed]

    %% NLP Subprocesses
    B2 --> F2[Tokenization]
    B2 --> G2[NLP Preprocessing]
    C2 --> H2[Transformer Model]
    C2 --> I2[Autoregressive Generation]

